{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Yy09ePlLejit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class MNIST(object):\n",
        "    def __init__(self, subset='train', batch_size=64, labeled_percent=0.2, shuffle=True):\n",
        "        mnist = input_data.read_data_sets('data', one_hot=False)\n",
        "        if subset == 'train':\n",
        "            images = mnist.train._images\n",
        "            labels = mnist.train._labels.reshape((-1, 1))\n",
        "            np.random.seed(100)\n",
        "            is_labeled = np.zeros((55000, 1))\n",
        "            labeled_images = np.random.permutation(np.arange(55000))[:int(labeled_percent * 55000)]\n",
        "            is_labeled[labeled_images] = 1\n",
        "            np.random.seed()\n",
        "        elif subset == 'valid':\n",
        "            images = mnist.validation._images\n",
        "            labels = mnist.validation._labels.reshape((-1, 1))\n",
        "            is_labeled = np.ones((5000, 1))\n",
        "        elif subset == 'test':\n",
        "            images = mnist.test._images\n",
        "            labels = mnist.test._labels.reshape((-1, 1))\n",
        "            is_labeled = np.ones((10000, 1))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        self._images = images\n",
        "        self.images = self._images\n",
        "        self._labels = labels\n",
        "        self.labels = self._labels\n",
        "        self._is_labeled = is_labeled\n",
        "        self.is_labeled = self._is_labeled\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = len(self.images)\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            self.shuffle_samples()\n",
        "        self.next_batch_pointer = 0\n",
        "\n",
        "    def shuffle_samples(self):\n",
        "        image_indices = np.random.permutation(np.arange(self.num_samples))\n",
        "        self.images = self._images[image_indices]\n",
        "        self.labels = self._labels[image_indices]\n",
        "        self.is_labeled = self._is_labeled[image_indices]\n",
        "\n",
        "    def get_next_batch(self):\n",
        "        num_samples_left = self.num_samples - self.next_batch_pointer\n",
        "        if num_samples_left >= self.batch_size:\n",
        "            x_batch = self.images[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            y_batch = self.labels[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            is_labeled_batch = self.is_labeled[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            self.next_batch_pointer += self.batch_size\n",
        "        else:\n",
        "            x_partial_batch_1 = self.images[self.next_batch_pointer:self.num_samples]\n",
        "            y_partial_batch_1 = self.labels[self.next_batch_pointer:self.num_samples]\n",
        "            is_labeled_batch_1 = self.is_labeled[self.next_batch_pointer:self.num_samples]\n",
        "            if self.shuffle:\n",
        "                self.shuffle_samples()\n",
        "            x_partial_batch_2 = self.images[0:self.batch_size - num_samples_left]\n",
        "            y_partial_batch_2 = self.labels[0:self.batch_size - num_samples_left]\n",
        "            is_labeled_batch_2 = self.is_labeled[0:self.batch_size - num_samples_left]\n",
        "            x_batch = np.vstack((x_partial_batch_1, x_partial_batch_2))\n",
        "            y_batch = np.vstack((y_partial_batch_1, y_partial_batch_2))\n",
        "            is_labeled_batch = np.vstack((is_labeled_batch_1, is_labeled_batch_2))\n",
        "            self.next_batch_pointer = self.batch_size - num_samples_left\n",
        "        return x_batch, y_batch, is_labeled_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdONnsNGh6vR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: (Optional)\n",
        "# Define your convenient function for convolution, batch_norm,... (if applicable)\n",
        "\n",
        "\n",
        "def AutoEncoder(input_tensor, is_training):\n",
        "    # input_tensor: image tensor, similar to previous assignment, size [N, 784]\n",
        "    # is_training: boolean tensor indicate whether if in training phase or testing phase\n",
        "\n",
        "    # TODO: Define the architecture of your autoencoder here\n",
        "    \n",
        "    # return:\n",
        "    # recon: reconstruction of the image by the autoencoder\n",
        "    # logits: logits of the classification branch from the bottleneck of the autoencoder\n",
        "    return recon, logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQn1wJE-i93O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "outputId": "08af2c6f-e641-40a7-e1c7-8c5990c01cd8"
      },
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    # General setup    \n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE = 64\n",
        "    NUM_ITERS = int(55000 / BATCH_SIZE * EPOCHS)\n",
        "\n",
        "    train_set = MNIST('train', batch_size=BATCH_SIZE)\n",
        "    valid_set = MNIST('valid')\n",
        "    test_set = MNIST('test', shuffle=False)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    x = tf.placeholder(tf.float32, (None, 784))\n",
        "    y = tf.placeholder(tf.int32, (None, 1))\n",
        "    is_labeled = tf.placeholder(tf.float32, (None, 1))\n",
        "    is_training = tf.placeholder(tf.bool, ())\n",
        "    one_hot_y = tf.one_hot(y, 10)\n",
        "\n",
        "    # create loss\n",
        "    rate = 0.01\n",
        "    recon, logits = AutoEncoder(x, is_training=is_training)\n",
        "    prediction = tf.argmax(logits, axis=1)\n",
        "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y) * is_labeled)\n",
        "    recon_loss = tf.reduce_mean((recon - x) ** 2)\n",
        "    loss_operation = cross_entropy + recon_loss\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
        "    grads_and_vars = optimizer.compute_gradients(loss_operation, tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
        "    training_operation = optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "    def evaluation(images, true_labels):\n",
        "        eval_batch_size = 100\n",
        "        predicted_labels = []\n",
        "        for start_index in range(0, len(images), eval_batch_size):\n",
        "            end_index = start_index + eval_batch_size\n",
        "            batch_x = images[start_index: end_index]\n",
        "            batch_predicted_labels = sess.run(prediction, feed_dict={x: batch_x, is_training: False})\n",
        "            predicted_labels += list(batch_predicted_labels)\n",
        "        predicted_labels = np.vstack(predicted_labels).flatten()\n",
        "        true_labels = true_labels.flatten()\n",
        "        accuracy = float((predicted_labels == true_labels).astype(np.int32).sum()) / len(images)\n",
        "        return predicted_labels, accuracy\n",
        "\n",
        "    # train\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"Training...\")\n",
        "    for i in range(NUM_ITERS):\n",
        "        batch_x, batch_y, batch_is_labeled = train_set.get_next_batch()\n",
        "        _ = sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, is_labeled: batch_is_labeled, is_training: True})\n",
        "        if (i + 1) % 1000 == 0 or i == NUM_ITERS - 1:\n",
        "            _, validation_accuracy = evaluation(valid_set._images, valid_set._labels)\n",
        "            print(\"Iter {}: Validation Accuracy = {:.3f}\".format(i, validation_accuracy))\n",
        "\n",
        "    print('Evaluating on test set')\n",
        "    _, test_accuracy = evaluation(test_set._images, test_set._labels)\n",
        "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
        "\n",
        "    sess.close()\n",
        "    return test_accuracy\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-6ae54b46df48>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-4-d048fb7cc885>:26: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Training...\n",
            "Iter 999: Validation Accuracy = 0.971\n",
            "Iter 1999: Validation Accuracy = 0.976\n",
            "Iter 2999: Validation Accuracy = 0.978\n",
            "Iter 3999: Validation Accuracy = 0.976\n",
            "Iter 4999: Validation Accuracy = 0.980\n",
            "Iter 5999: Validation Accuracy = 0.981\n",
            "Iter 6999: Validation Accuracy = 0.982\n",
            "Iter 7999: Validation Accuracy = 0.983\n",
            "Iter 8592: Validation Accuracy = 0.981\n",
            "Evaluating on test set\n",
            "Test Accuracy = 0.978\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}